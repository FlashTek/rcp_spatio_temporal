\chapter{Anwendungen}
\label{ch:experiments}

Die zuvor in Kapitel \ref{ch:theory} eingeführten Methoden werden nun durch drei verschiedene Szenarien ausprobiert und verglichen. Hierbei liegt der Fokus auf der Verwendung und Erprobung der \textsc{ESN}s. Da die klassischen Methoden der \textit{nächsten Nachbarn} (\textsc{NN}) und der \textit{radialen Basisfunktionen} (\textsc{RBF}) bereits seit längerer Zeit bekannt sind und populäre Lösung solcher Problemfälle darstellen, dienen sie als Bezugsgröße.\\

Jedes der drei Szenarien wird sowohl auf ein \textit{Barkley}-System als auch auf ein System nach dem \textit{Mitchell-Schaeffer}-Modell angewendet. Diese Systeme bestehen aus $150$ Gitterpunkten und nutzen die zuvor beschriebenen Parameter. Für ihre Startverteilung werden die Felder der beiden Systemvariablen in $100$ Quadrate unterteilt, und diese mit Zufallswerten zwischen $0$ und $1$ initialisiert. Anschließend werden die Systeme über $20000$ Zeitschritte ($\widehat{=} 200.0$ Zeiteinheiten) simuliert um ein transientes Verhalten abzuwarten. Durch das weitere Simulieren der Systeme wird der wirkliche Datensatz generiert, der benutzt wird. Dieser wird in einen Trainingsdatensatz, einen Evaluationsdatensatz und einen Testdatensatz aufgeteilt. Der erste wird für das Trainieren der Modelle und Ansätze verwendet, der zweite für das Auswählen der optimalen Hyperparameter und der dritte für die finale Bewertung der Leistung eines Ansatzes. Es wird für das \textit{Barkley}- eine Samplingzeit von $0.1$ und für das \textit{Mitchell-Schaeffer}-Modell von $1.0$ Zeiteinheiten benutzt.\\
 
Die erste Aufgabe besteht darin aus der Kenntnis einer der beiden Systemvariablen die andere Unbekannte zu ermitteln. Dabei wird die Spannungsvariable als Quelle genutzt. Dies ist in den zuvor eingeführten Modellen jeweils die Größe, welche den Diffusionsterm beinhaltet; also die $u$-Variable im \textit{Barkley}-Modell und die $v$-Variable im \textit{Mitchell-Schaeffer}-Modell.\\
Im zweiten Szenario werden die Techniken verwendet um aus Messdaten einer simulierten Fernfeldmessung der Spannungsvariable  diese wiederherzustellen. Diese Fernfeldmessung wird durch eine gaußsche Unschärfe simuliert.\\
Abschließend wird die Spannungsvariable der inneren Punkte eines Quadrates nur durch die Kenntnis der Randwerte des Systems vorhergesagt.\\

\unsure{Add subchapter?}
\section{Allgemeines Vorgehen}
\label{sc:experiments_general}
Das Ziel aller drei Aufgaben besteht jeweils darin ein zweidimensionales Feld vorherzusagen. Eine naheliegende Möglichkeit dies zu schaffen besteht darin wirklich den gesamten Inhalt des $150 \times 150$ Einheiten großen Feldes auf einmal vorherzusagen. Da dabei die Ausgabe der Vorhersage aus einem $22500$-dimensionalen Vektor besteht werden sehr viele Trainingsdaten benötigt, um genügend Informationen über eine solch hochdimensionale Ausgabe zu erhalten. Um dieses Problem zu umgehen wird stattdessen ein Verfahren benutzt, bei dem jeder Punkt einzeln vorhergesagt wird. Dieses Aufteilen einer großen Vorhersage in viele kleinere bietet zudem eine Verbesserung der Ressourcennutzung, bei der zugleich der Bedarf an Arbeitsspeicher und auch die Rechenzeit sinkt (Details siehe \ref{exp_general_esn}).\\

\begin{figure}[h]
\centering
\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[width=.8\linewidth]{figures/illustrations/sigma_patches.pdf}
  \caption{Messsonde ohne Abstände zwischen\\den Messpunkten}
  \label{fig:probe_illustration_no_gaps}
\end{subfigure}%
\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[width=.8\linewidth]{figures/illustrations/sigma_patches_gaps.pdf}
  \caption{Messonde mit einem Abstand von zwei Einheiten zwischen den Messpunkten}
  \label{fig:probe_illustration_gaps}
\end{subfigure}
\caption{Illustration der verwendeten \textit{Messsondentechnik}. Abbildung \ref{fig:probe_illustration_no_gaps} deutet an, wie aus einem $\sigma^2$ großem Quadrat um den eigentlichen Messpunkt Daten für die Vorhersage genutzt werden. Dagegen ist in Abbildung \ref{fig:probe_illustration_gaps} das Verfahren für $\sigma=5$ und $\Delta \sigma = 2$ dargestellt, sodass insgesamt die Information aus $9$ Punkten genutzt wird.}
\label{fig:probe_illustration}
\end{figure}

Des Weiteren kann angenommen werden, dass die Dynamiken einen ausgeprägten lokalen Charakter besitzen, sodass zumindest bei den ersten beiden Aufgaben weit entfernte Punkte keinen unmittelbaren Einfluss auf die Vorhersage haben. Darauf basierend kann eine sogenannte \textit{Messsondentechnik} entwickelt und für diese genutzt werden. Hierbei werden nicht nur die Informationen an einem Punkt $(i, j)$ für die Vorhersage, sondern auch die benachbarten Punkte, welche in einem Quadrat um $(i, j)$ liegen, genutzt. Eine Veranschaulichung ist in \ref{fig:probe_illustration_no_gaps} zu finden. Die Größe des Quadrates wird durch den Parameter $\sigma$ bestimmt, und ergibt sich zu $\sigma^2$. Da direkt Nachbarn unter Umständen durch den geringen Abstand sehr ähnliche Informationen beinhalten können, wird zudem ein Parameter $\Delta \sigma$ eingeführt, welche den Abstand zweier benachbarter Punkte, deren Information simultan verwendet werden, angibt. Eine beispielhafte Darstellung hiervon ist für $\sigma = 5, \Delta \sigma=2$ in Abbildung \ref{fig:probe_illustration_gaps} dargestellt. Dabei werden nur die Zeitreihen der Gitterpunkte genutzt, welche dunkelgrau hinterlegt sind, und die hellgrauen Informationen verworfen. Die Parameter, welche für die ersten beiden Aufgaben überprüft werden, sind in Tabelle \ref{tab:probe_sigma_values} aufgelistet. Dabei ist anzumerken, dass die Diskretisierung des Diffusionstermes in den Differentialgleichungen einem Wert $\sigma=3$ entsprechen würde.\\
Durch dieses Vorgehen kann für jeden Gitterpunkt ein ${\left \lceil{\frac{\sigma}{\Delta \sigma}}\right \rceil}^2$-dimensionaler Eingabevektor erstellt und für die ersten beiden Vorhersage-Aufgaben genutzt werden.\\

\begin{table}[h]
\centering
\begin{tabular}{cc|c|c|c|c|c|c}
\hline
$\sigma$ & 1 & 3 & \multicolumn{2}{c|}{5} & \multicolumn{3}{c}{7} \\
\hline
$\Delta \sigma$ & 1 & 1 & 1 & 2 & 1 & 2 & 3 \\
\hline
\end{tabular} 
\caption{In den ersten beiden Aufgaben verwendete Parameter $\sigma$ und $\Delta \sigma$ für die \textit{Messsondentechnik}.}
\label{tab:probe_sigma_values}
\end{table} 

Der Trainingsvorgang wird jeweils über $N_{Training}=15000$ Zeitschritte durchgeführt und der anschließende Evaluationsdurchgang auf $N_{Evaluation} = 2000$ Zeitschritte. Der finale Testvorgang ist ebenfalls $N_{Testing}=2000$ Schritte lang.
Zur Bewertung der Leistung einer Vorhersage werden die beiden Fehlergrößen MSE und NRMSE eingeführt. Im Allgemeinen ist der MSE (\textit{Mean Squared Error}) durch
\begin{align}
MSE(y) = \sum_i^m \sum_t^{N_{Testing}} \left(y(t)_i - \hat{y}(t)_i \right)^2
\end{align}
definiert und charakterisiert die Genauigkeit einer Vorhersage $\hat{y}$ im Vergleich zu dem tatsächlichen Wert $y \in \mathbb{R}^m$ über den Zeitraum $N_{Testing}$. Der NRMSE normiert diesen Fehler noch auf eine Vorhersage, bei der der Mittelwert $\langle y \rangle$ über die Trainingsphase als vorhergesagten Wert genutzt wird. Er ist als
\begin{align}
NRMSE(y) = \sqrt{\frac{MSE(y)}{MSE\left(\langle y \rangle\right)}}
\end{align}
definiert. Ein NRMSE von $0.0$ steht für eine optimale Vorhersage. Steigt der NRMSE auf $>1.0$ an, so ist die Vorhersage mittels des Mittelwertes des Trainingsdatensatzes präziser als die zuvor bestimmte Vorhersage.\\
Zusätzlich zu diesen Fehlermaßen werden im Folgenden oftmals auch die Laufzeiten der Ansätze angegeben. Hierbei ist zu beachten, dass diese nicht über mehrere Ausführungen des identischen Programmes gemittelt worden sind, und deshalb nicht als statistisch relevante Information sondern nur als ein Hinweis gesehen werden können.\\

Unter der Kenntnis, dass in den Modellen nur Werte zwischen $0$ und $1$ angenommen werden dürfen beziehungsweise angenommen werden, werden die Vorhersagen auf das Intervall $[0, 1]$ beschränkt. Dafür werden die Werte beider Variablen der Systeme sowohl nach unten als auch nach oben hin nach 
\begin{align}
x = \begin{cases}
	0,& \text{wenn } x \leq 0\\
	x,& \text{wenn } x \geq 0 \land \leq 1\\
    1,& \text{wenn } x \geq 1
\end{cases}
\end{align}
abgeschnitten, wobei $x$ für eine der beiden Variablen in dem jeweiligen Modell steht.\\

Zur Erprobung verschiedener Hyperparameter innerhalb der verschiedenen Ansätze ist ein \textsc{Sun Grid Engine}-Cluster genutzt worden. Dabei besteht jeder Knoten aus zwei \textsc{Intel(R) Xeon(R) CPU E5-2650 v2} CPUs mit einem Takt von $2.650$ GHz und $64$ GB Arbeitsspeicher. Diese werden durch das Betriebssystem \textsc{SUSE Linux Enterprise Server 11} betrieben. Die angegebenen Laufzeiten beziehen sich jeweils auf die Ausführung auf einem dieser Knoten. 
\improvement{Add moreinformation about the cluster}


\FloatBarrier
\subsection{Echo State Network}
\label{sec:exp_general_esn}
\textit{Echo State Networks} besitzen viele verschiedene Hyperparameter, welche die Qualität der Vorhersage beeinflussen können. Dazu zählen nach \ref{sc:esn} die Reservoirgröße $N$, der Spektralradius $\rho$, die Verlustrate $\alpha$, die Amplitude der zufälligen Störung $\nu$, die Stärke der Regularisierung $\lambda$ und der Anteil der vorhandenen internen Verbindungen $\epsilon$. Da es zum aktuellen Zeitpunkt noch keinen zufriendenstellenden mathematischen Algorithmus für das das selbstständige optimale Einstellen eines \textsc{ESN}s gibt, müssen die Parameter manuell ermittelt werden. Hierfür wird in dieser Arbeit eine \textsc{GridSearch} benutzt. Bei diesem Verfahren wird der Hyperparameterraum in festgelegten Schritten abgetastet und die Leistung des somit entstehenden Netzwerke evaluiert und somit die besten Parameter ermittelt. Durch die hohe Anzahl der einstellbaren Hyperparameter und die nicht zu vernachlässigende Rechenzeit für das Trainieren und Evaluieren eines Netzwerkes, ist es nicht sinnvoll diese Suche für alle Komponenten des hochdimensionalen Zielvektors gleichzeitig durchzuführen. Stattdessen wird zuerst unter der Annahme, dass die Dynamik sich lokal an allen Punkten ähnlich verhält, ein Punkt in der Mitte des Feldes ausgewählt, und nur versucht diesen einen einzelnen Punkt vorherzusagen. Diese Aufgabe kann deutlich schneller berechnet werden, sodass nun die optimalen Hyperparameter mit einer \textsc{GridSearch} gesucht werden können. Im Anschluss können die Hyperparameter des  zuvor ermittelten \textsc{ESN} für die Vorhersage aller Punkte genutzt werden. Abschließend wird noch einmal Versucht das gefundene Reservoir manuell zu verbessern, indem die Parameter $N$ und $\lambda$ noch einmal variiert werden.\\
Es ist zu erwarten, dass die hierbei gefundenen Hyperparameter eine akzeptable Leistung für die jeweiligen Probleme erzielen können. Da allerdings bei dem zuvor beschriebenen Verfahren bei weitem nicht alle sinnvollen Hyperparameter getestet werden können, besteht die Möglichkeit, dass es noch besser geeignete Reservoirs mit anderen Hyperparametern gibt, welche eine noch höhere Leistung erzielen können.\\

Statt für jeden Punkt einzeln eine Vorhersage zu treffen, ist es bei einem Reservoir-Ansatz auch vorstellbar alle Punkte gleichzeitig vorherzusagen und dabei innerhalb des Reservoirs die räumliche Struktur der Dynamik stärker abzubilden. Hierfür wäre ein sehr großes Reservoir, welches etwa so viele Einheiten besitzt, wie es Gitterpunkte gibt, vorstellbar. Da nach Anhang \ref{sc:apx_runtime_complexity} die Laufzeit des \textsc{ESN} allerdings mit mindestens $\mathcal{O}(N^{2.376})$ anwächst, würde die Laufzeit mit $(N_{Gitter}^2)^{2.376}$ anwachsen. Dahingegen wächst die Laufzeit mit dem zuvor vorgestellten Ansatz mit $(N_{Gitter})^2 \cdot N^{2.376}$, wobei $N$ die Anzahl der internen Einheiten ist. Es ist zu erkennen, dass für hinreichend große Gittergrößen die Laufzeit des großen Ansatzes stärker anwächst als das obige Vorgehen. Zudem lässt sich das zuvor vorgestellte Verfahren auch besser Parallelisieren, da die Vorhersage jedes einzelnen Punktes unabhängig von der Vorhersage der übrigen Punkte ist.   
\improvement{Add plot to show the developement of the curves?}

\FloatBarrier
\subsection{Klassische Methoden}
Die klassischen Methoden sind nicht von alleine aus in der Lage zeitlich ausgeprägte Dynamiken vorherzusagen, da den Methoden a priori keine Informationen über die vorherigen Zustände vorliegen. Um dieses Problem zu lösen können Verzögerungs-Koordinaten mittels der in Abschnitt \ref{sc:delay_reconstruction} beschriebenen \textit{Delay Reconstruction} für die in Abschnitt \ref{sc:experiments_general} beschriebenen Vektoren aufgestellt werden. Die über die Autokorrelation ermittelte zeitliche Verzögerung $\tau$ ist für beide Systeme in Tabelle \ref{tab:delay_reconstruction_tau} dargestellt.     

\begin{table}[h]
\centering
\begin{tabular}{cc}
\hline
$\tau_{Barkley}$ & $\tau_{Mitchell-Schaeffer}$ \\ 
0.64 Zeiteinheiten & 2.38 Zeiteinheiten\\ 
\hline 
\end{tabular} 
\caption{Verwendete zeitliche Verzögerung $\tau$ für die \textit{Delay Reconstruction} für das \textit{Mitchell-Schaeffer}- und das \textit{Barkley}-Modell}
\label{tab:delay_reconstruction_tau}
\end{table} 

\input{content/cross_pred.tex}
\input{content/unblur_pred.tex}
\input{content/inner_cross_pred.tex}